# Task 3 â€“ Image Captioning AI ğŸ“·ğŸ“

This project generates natural language captions for images using computer vision and NLP.

## ğŸ§  How It Works:
- Uses **Vision Transformer (ViT)** to extract image features
- Uses **GPT-2** to generate natural language captions
- Built using HuggingFace's `vit-gpt2-image-captioning` model

## âœ… Features:
- Accepts any image input
- Returns meaningful captions like:
  - ğŸ± "a cat sitting on a windowsill looking outside"
  - ğŸ”ï¸ "a mountain range with snow covered peaks"
  - ğŸ™ï¸ "a city skyline with tall buildings at night"

## ğŸ“‚ Project Files:
- `image_captioning.ipynb` â€“ main notebook
- `/images/` â€“ test images
- `README.md` â€“ this file

## ğŸ“š Libraries Used:
- Transformers
- TensorFlow
- PIL
- Matplotlib

## ğŸ§  Learning Outcome:
This task helped me understand how **computer vision and NLP** can be combined using modern transformer-based models.

---

#codsoft #internship #imagecaptioning #cv #nlp #transformers #vit #gpt2 #ai
